{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "I'll help you create an OCR system for restaurant bills/menus. Here's a complete Jupyter notebook for testing OCR accuracy and a FastAPI implementation:\n",
            "\n",
            "## 1. OCR Algorithm Development Notebook"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# !pip install cv2"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "ename": "ModuleNotFoundError",
               "evalue": "No module named 'cv2'",
               "output_type": "error",
               "traceback": [
                  "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                  "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# restaurant_ocr_testing.ipynb\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytesseract\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
                  "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
               ]
            }
         ],
         "source": [
            "# restaurant_ocr_testing.ipynb\n",
            "import cv2\n",
            "import pytesseract\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "from PIL import Image\n",
            "import re\n",
            "import json\n",
            "import warnings\n",
            "warnings.filterwarnings('ignore')\n",
            "\n",
            "# Set tesseract path (adjust based on your installation)\n",
            "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Windows\n",
            "# For Linux/Mac: usually installed in PATH\n",
            "\n",
            "print(\"Restaurant Bill/Menu OCR Testing System\")\n",
            "print(\"=\" * 50)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Image Preprocessing Functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def preprocess_image(image_path):\n",
            "    \"\"\"\n",
            "    Preprocess image for better OCR accuracy\n",
            "    \"\"\"\n",
            "    # Read image\n",
            "    img = cv2.imread(image_path)\n",
            "    if img is None:\n",
            "        raise ValueError(f\"Could not load image from {image_path}\")\n",
            "    \n",
            "    # Convert to grayscale\n",
            "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
            "    \n",
            "    # Noise removal\n",
            "    denoised = cv2.medianBlur(gray, 3)\n",
            "    \n",
            "    # Thresholding\n",
            "    _, thresh = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
            "    \n",
            "    # Morphological operations to clean image\n",
            "    kernel = np.ones((1, 1), np.uint8)\n",
            "    processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
            "    processed = cv2.morphologyEx(processed, cv2.MORPH_OPEN, kernel)\n",
            "    \n",
            "    return img, gray, processed\n",
            "\n",
            "def display_images(original, processed, title=\"Image Comparison\"):\n",
            "    \"\"\"\n",
            "    Display original and processed images side by side\n",
            "    \"\"\"\n",
            "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
            "    \n",
            "    axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
            "    axes[0].set_title('Original Image')\n",
            "    axes[0].axis('off')\n",
            "    \n",
            "    axes[1].imshow(processed, cmap='gray')\n",
            "    axes[1].set_title('Processed Image')\n",
            "    axes[1].axis('off')\n",
            "    \n",
            "    plt.tight_layout()\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### OCR Extraction Functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def extract_text_with_tesseract(image, config='--psm 6'):\n",
            "    \"\"\"\n",
            "    Extract text using Tesseract OCR\n",
            "    \"\"\"\n",
            "    text = pytesseract.image_to_string(image, config=config)\n",
            "    return text.strip()\n",
            "\n",
            "def extract_detailed_data(image):\n",
            "    \"\"\"\n",
            "    Extract detailed data with bounding boxes\n",
            "    \"\"\"\n",
            "    data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
            "    return data\n",
            "\n",
            "def extract_text_with_different_psm(image_path):\n",
            "    \"\"\"\n",
            "    Try different Page Segmentation Modes for better accuracy\n",
            "    \"\"\"\n",
            "    _, _, processed_img = preprocess_image(image_path)\n",
            "    \n",
            "    psm_modes = {\n",
            "        3: 'Fully automatic page segmentation',\n",
            "        4: 'Assume single column of text',\n",
            "        6: 'Assume uniform block of text',\n",
            "        8: 'Single word',\n",
            "        11: 'Sparse text'\n",
            "    }\n",
            "    \n",
            "    results = {}\n",
            "    for psm, desc in psm_modes.items():\n",
            "        config = f'--psm {psm}'\n",
            "        text = extract_text_with_tesseract(processed_img, config)\n",
            "        results[psm] = {\n",
            "            'description': desc,\n",
            "            'text': text,\n",
            "            'line_count': len(text.split('\\n'))\n",
            "        }\n",
            "    \n",
            "    return results"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Restaurant Bill Parser"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "class RestaurantBillParser:\n",
            "    def __init__(self):\n",
            "        self.menu_items_keywords = [\n",
            "            'burger', 'pizza', 'pasta', 'salad', 'soup', 'sandwich',\n",
            "            'chicken', 'beef', 'fish', 'rice', 'noodles', 'fries',\n",
            "            'coffee', 'tea', 'juice', 'water', 'soda', 'beer', 'wine'\n",
            "        ]\n",
            "        \n",
            "        self.price_pattern = r'\\$?\\d+\\.?\\d{0,2}'\n",
            "        self.quantity_pattern = r'(\\d+)\\s*x'\n",
            "    \n",
            "    def parse_bill_text(self, text):\n",
            "        \"\"\"\n",
            "        Parse OCR text into structured bill data\n",
            "        \"\"\"\n",
            "        lines = text.split('\\n')\n",
            "        parsed_data = {\n",
            "            'restaurant_name': '',\n",
            "            'items': [],\n",
            "            'subtotal': 0,\n",
            "            'tax': 0,\n",
            "            'total': 0,\n",
            "            'date': '',\n",
            "            'raw_text': text\n",
            "        }\n",
            "        \n",
            "        # Extract items and prices\n",
            "        items = []\n",
            "        current_item = {}\n",
            "        \n",
            "        for line in lines:\n",
            "            line = line.strip()\n",
            "            if not line:\n",
            "                continue\n",
            "                \n",
            "            # Look for prices in the line\n",
            "            prices = re.findall(self.price_pattern, line)\n",
            "            \n",
            "            if prices:\n",
            "                # Remove prices from line to get item name\n",
            "                item_name = re.sub(self.price_pattern, '', line).strip()\n",
            "                item_name = re.sub(r'[^\\w\\s]', '', item_name).strip()\n",
            "                \n",
            "                if len(item_name) > 2:  # Filter out very short \"items\"\n",
            "                    price = float(prices[-1].replace('$', ''))\n",
            "                    \n",
            "                    # Look for quantity\n",
            "                    quantity_match = re.search(self.quantity_pattern, line.lower())\n",
            "                    quantity = int(quantity_match.group(1)) if quantity_match else 1\n",
            "                    \n",
            "                    items.append({\n",
            "                        'name': item_name,\n",
            "                        'quantity': quantity,\n",
            "                        'unit_price': price / quantity,\n",
            "                        'total_price': price\n",
            "                    })\n",
            "            \n",
            "            # Look for totals\n",
            "            if any(keyword in line.lower() for keyword in ['total', 'subtotal', 'tax']):\n",
            "                prices = re.findall(self.price_pattern, line)\n",
            "                if prices:\n",
            "                    price_val = float(prices[0].replace('$', ''))\n",
            "                    if 'subtotal' in line.lower():\n",
            "                        parsed_data['subtotal'] = price_val\n",
            "                    elif 'tax' in line.lower():\n",
            "                        parsed_data['tax'] = price_val\n",
            "                    elif 'total' in line.lower():\n",
            "                        parsed_data['total'] = price_val\n",
            "        \n",
            "        parsed_data['items'] = items\n",
            "        return parsed_data\n",
            "    \n",
            "    def parse_menu_text(self, text):\n",
            "        \"\"\"\n",
            "        Parse OCR text into structured menu data\n",
            "        \"\"\"\n",
            "        lines = text.split('\\n')\n",
            "        parsed_data = {\n",
            "            'restaurant_name': '',\n",
            "            'sections': {},\n",
            "            'items': [],\n",
            "            'raw_text': text\n",
            "        }\n",
            "        \n",
            "        current_section = 'Main'\n",
            "        items = []\n",
            "        \n",
            "        for line in lines:\n",
            "            line = line.strip()\n",
            "            if not line:\n",
            "                continue\n",
            "            \n",
            "            # Check if line is a section header\n",
            "            if (line.isupper() or \n",
            "                any(keyword in line.lower() for keyword in ['appetizer', 'main', 'dessert', 'drink', 'entree']) or\n",
            "                line.endswith(':')):\n",
            "                current_section = line.replace(':', '').strip()\n",
            "                parsed_data['sections'][current_section] = []\n",
            "                continue\n",
            "            \n",
            "            # Look for prices in the line\n",
            "            prices = re.findall(self.price_pattern, line)\n",
            "            \n",
            "            if prices:\n",
            "                # Extract item name and description\n",
            "                item_text = re.sub(self.price_pattern, '', line).strip()\n",
            "                price = float(prices[0].replace('$', ''))\n",
            "                \n",
            "                items.append({\n",
            "                    'name': item_text,\n",
            "                    'price': price,\n",
            "                    'section': current_section,\n",
            "                    'description': ''\n",
            "                })\n",
            "                \n",
            "                if current_section in parsed_data['sections']:\n",
            "                    parsed_data['sections'][current_section].append({\n",
            "                        'name': item_text,\n",
            "                        'price': price\n",
            "                    })\n",
            "        \n",
            "        parsed_data['items'] = items\n",
            "        return parsed_data"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Testing and Accuracy Evaluation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def test_ocr_accuracy(test_images):\n",
            "    \"\"\"\n",
            "    Test OCR accuracy on sample images\n",
            "    \"\"\"\n",
            "    results = []\n",
            "    parser = RestaurantBillParser()\n",
            "    \n",
            "    for img_path in test_images:\n",
            "        print(f\"\\nTesting: {img_path}\")\n",
            "        print(\"-\" * 40)\n",
            "        \n",
            "        try:\n",
            "            # Preprocess image\n",
            "            original, gray, processed = preprocess_image(img_path)\n",
            "            \n",
            "            # Display images\n",
            "            display_images(original, processed, f\"OCR Processing: {img_path}\")\n",
            "            \n",
            "            # Extract text with different PSM modes\n",
            "            psm_results = extract_text_with_different_psm(img_path)\n",
            "            \n",
            "            # Use best PSM mode (usually 6 for bills)\n",
            "            best_text = psm_results[6]['text']\n",
            "            \n",
            "            print(\"Extracted Text:\")\n",
            "            print(best_text)\n",
            "            print(\"\\n\" + \"=\"*50)\n",
            "            \n",
            "            # Parse the text\n",
            "            if 'menu' in img_path.lower():\n",
            "                parsed_data = parser.parse_menu_text(best_text)\n",
            "                data_type = 'menu'\n",
            "            else:\n",
            "                parsed_data = parser.parse_bill_text(best_text)\n",
            "                data_type = 'bill'\n",
            "            \n",
            "            print(f\"Parsed {data_type.upper()} Data:\")\n",
            "            print(json.dumps(parsed_data, indent=2))\n",
            "            \n",
            "            # Calculate basic accuracy metrics\n",
            "            text_length = len(best_text)\n",
            "            word_count = len(best_text.split())\n",
            "            non_empty_lines = len([line for line in best_text.split('\\n') if line.strip()])\n",
            "            \n",
            "            results.append({\n",
            "                'image': img_path,\n",
            "                'text_length': text_length,\n",
            "                'word_count': word_count,\n",
            "                'lines_extracted': non_empty_lines,\n",
            "                'data_type': data_type,\n",
            "                'parsed_successfully': len(parsed_data['items']) > 0,\n",
            "                'items_found': len(parsed_data['items'])\n",
            "            })\n",
            "            \n",
            "        except Exception as e:\n",
            "            print(f\"Error processing {img_path}: {str(e)}\")\n",
            "            results.append({\n",
            "                'image': img_path,\n",
            "                'error': str(e),\n",
            "                'parsed_successfully': False\n",
            "            })\n",
            "    \n",
            "    return results\n",
            "\n",
            "# Example usage\n",
            "if __name__ == \"__main__\":\n",
            "    # Replace with your test image paths\n",
            "    test_images = [\n",
            "        'sample_bill_1.jpg',\n",
            "        'sample_bill_2.jpg',\n",
            "        'sample_menu_1.jpg'\n",
            "    ]\n",
            "    \n",
            "    # Test OCR accuracy\n",
            "    accuracy_results = test_ocr_accuracy(test_images)\n",
            "    \n",
            "    # Display results summary\n",
            "    df_results = pd.DataFrame(accuracy_results)\n",
            "    print(\"\\nOCR Accuracy Results Summary:\")\n",
            "    print(\"=\" * 50)\n",
            "    print(df_results)\n",
            "    \n",
            "    # Calculate success rate\n",
            "    successful_parses = df_results[df_results['parsed_successfully'] == True]\n",
            "    success_rate = len(successful_parses) / len(df_results) * 100\n",
            "    \n",
            "    print(f\"\\nOverall Success Rate: {success_rate:.2f}%\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Performance Optimization"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def optimize_ocr_performance():\n",
            "    \"\"\"\n",
            "    Test different preprocessing techniques for optimal performance\n",
            "    \"\"\"\n",
            "    techniques = {\n",
            "        'default': lambda img: img,\n",
            "        'denoise_only': lambda img: cv2.medianBlur(img, 3),\n",
            "        'threshold_only': lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1],\n",
            "        'morphology_only': lambda img: cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((1,1), np.uint8))\n",
            "    }\n",
            "    \n",
            "    performance_results = []\n",
            "    \n",
            "    for tech_name, tech_func in techniques.items():\n",
            "        try:\n",
            "            # Test on sample image\n",
            "            img_path = 'sample_bill_1.jpg'  # Replace with actual path\n",
            "            original, gray, _ = preprocess_image(img_path)\n",
            "            \n",
            "            # Apply technique\n",
            "            processed = tech_func(gray)\n",
            "            \n",
            "            # Measure performance\n",
            "            start_time = time.time()\n",
            "            text = extract_text_with_tesseract(processed)\n",
            "            end_time = time.time()\n",
            "            \n",
            "            performance_results.append({\n",
            "                'technique': tech_name,\n",
            "                'processing_time': end_time - start_time,\n",
            "                'text_length': len(text),\n",
            "                'word_count': len(text.split())\n",
            "            })\n",
            "            \n",
            "        except Exception as e:\n",
            "            print(f\"Error with {tech_name}: {str(e)}\")\n",
            "    \n",
            "    return pd.DataFrame(performance_results)\n",
            "\n",
            "# Run optimization tests\n",
            "performance_df = optimize_ocr_performance()\n",
            "print(\"Performance Comparison:\")\n",
            "print(performance_df)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 2. FastAPI Implementation\n",
            "\n",
            "Here's the FastAPI implementation that uses the OCR algorithm:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# main.py\n",
            "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
            "from fastapi.middleware.cors import CORSMiddleware\n",
            "from pydantic import BaseModel\n",
            "import uvicorn\n",
            "import cv2\n",
            "import pytesseract\n",
            "import numpy as np\n",
            "from PIL import Image\n",
            "import io\n",
            "import re\n",
            "import json\n",
            "from typing import List, Optional\n",
            "import logging\n",
            "\n",
            "# Configure logging\n",
            "logging.basicConfig(level=logging.INFO)\n",
            "logger = logging.getLogger(__name__)\n",
            "\n",
            "app = FastAPI(title=\"Restaurant OCR API\", version=\"1.0.0\")\n",
            "\n",
            "# CORS middleware\n",
            "app.add_middleware(\n",
            "    CORSMiddleware,\n",
            "    allow_origins=[\"*\"],\n",
            "    allow_credentials=True,\n",
            "    allow_methods=[\"*\"],\n",
            "    allow_headers=[\"*\"],\n",
            ")\n",
            "\n",
            "class MenuItem(BaseModel):\n",
            "    name: str\n",
            "    price: float\n",
            "    section: str\n",
            "    description: Optional[str] = \"\"\n",
            "\n",
            "class BillItem(BaseModel):\n",
            "    name: str\n",
            "    quantity: int\n",
            "    unit_price: float\n",
            "    total_price: float\n",
            "\n",
            "class MenuResponse(BaseModel):\n",
            "    restaurant_name: str\n",
            "    sections: dict\n",
            "    items: List[MenuItem]\n",
            "    raw_text: str\n",
            "    confidence: float\n",
            "\n",
            "class BillResponse(BaseModel):\n",
            "    restaurant_name: str\n",
            "    items: List[BillItem]\n",
            "    subtotal: float\n",
            "    tax: float\n",
            "    total: float\n",
            "    raw_text: str\n",
            "    confidence: float\n",
            "\n",
            "class RestaurantOCRProcessor:\n",
            "    def __init__(self):\n",
            "        self.price_pattern = r'\\$?\\d+\\.?\\d{0,2}'\n",
            "        self.quantity_pattern = r'(\\d+)\\s*x'\n",
            "    \n",
            "    def preprocess_image(self, image_bytes):\n",
            "        \"\"\"Preprocess uploaded image for OCR\"\"\"\n",
            "        try:\n",
            "            # Convert bytes to numpy array\n",
            "            nparr = np.frombuffer(image_bytes, np.uint8)\n",
            "            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
            "            \n",
            "            # Convert to grayscale\n",
            "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
            "            \n",
            "            # Noise removal and thresholding\n",
            "            denoised = cv2.medianBlur(gray, 3)\n",
            "            _, thresh = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
            "            \n",
            "            return thresh\n",
            "        except Exception as e:\n",
            "            logger.error(f\"Image preprocessing error: {str(e)}\")\n",
            "            raise\n",
            "    \n",
            "    def extract_text(self, processed_image):\n",
            "        \"\"\"Extract text from processed image\"\"\"\n",
            "        try:\n",
            "            # Use Tesseract with optimized configuration\n",
            "            custom_config = r'--psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz$.,:/()- '\n",
            "            text = pytesseract.image_to_string(processed_image, config=custom_config)\n",
            "            \n",
            "            # Get confidence data\n",
            "            data = pytesseract.image_to_data(processed_image, output_type=pytesseract.Output.DICT)\n",
            "            confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]\n",
            "            avg_confidence = sum(confidences) / len(confidences) if confidences else 0\n",
            "            \n",
            "            return text.strip(), avg_confidence\n",
            "        except Exception as e:\n",
            "            logger.error(f\"OCR extraction error: {str(e)}\")\n",
            "            raise\n",
            "    \n",
            "    def parse_menu(self, text):\n",
            "        \"\"\"Parse OCR text as menu\"\"\"\n",
            "        lines = text.split('\\n')\n",
            "        parsed_data = {\n",
            "            'restaurant_name': '',\n",
            "            'sections': {},\n",
            "            'items': [],\n",
            "            'raw_text': text\n",
            "        }\n",
            "        \n",
            "        current_section = 'Main'\n",
            "        \n",
            "        for line in lines:\n",
            "            line = line.strip()\n",
            "            if not line:\n",
            "                continue\n",
            "            \n",
            "            # Detect section headers\n",
            "            if (line.isupper() or \n",
            "                any(keyword in line.lower() for keyword in ['appetizer', 'main', 'entree', 'dessert', 'drink', 'beverage']) or\n",
            "                line.endswith(':')):\n",
            "                current_section = line.replace(':', '').strip()\n",
            "                parsed_data['sections'][current_section] = []\n",
            "                continue\n",
            "            \n",
            "            # Extract items with prices\n",
            "            prices = re.findall(self.price_pattern, line)\n",
            "            if prices:\n",
            "                item_text = re.sub(self.price_pattern, '', line).strip()\n",
            "                item_text = re.sub(r'[^\\w\\s]', ' ', item_text).strip()\n",
            "                \n",
            "                if len(item_text) > 2:\n",
            "                    price = float(prices[0].replace('$', ''))\n",
            "                    \n",
            "                    item_data = {\n",
            "                        'name': item_text,\n",
            "                        'price': price,\n",
            "                        'section': current_section\n",
            "                    }\n",
            "                    \n",
            "                    parsed_data['items'].append(item_data)\n",
            "                    if current_section in parsed_data['sections']:\n",
            "                        parsed_data['sections'][current_section].append(item_data)\n",
            "        \n",
            "        return parsed_data\n",
            "    \n",
            "    def parse_bill(self, text):\n",
            "        \"\"\"Parse OCR text as bill\"\"\"\n",
            "        lines = text.split('\\n')\n",
            "        parsed_data = {\n",
            "            'restaurant_name': '',\n",
            "            'items': [],\n",
            "            'subtotal': 0.0,\n",
            "            'tax': 0.0,\n",
            "            'total': 0.0,\n",
            "            'raw_text': text\n",
            "        }\n",
            "        \n",
            "        for line in lines:\n",
            "            line = line.strip()\n",
            "            if not line:\n",
            "                continue\n",
            "            \n",
            "            prices = re.findall(self.price_pattern, line)\n",
            "            \n",
            "            if prices and len(prices) == 1:\n",
            "                # Single price - likely an item\n",
            "                item_name = re.sub(self.price_pattern, '', line).strip()\n",
            "                item_name = re.sub(r'[^\\w\\s]', ' ', item_name).strip()\n",
            "                \n",
            "                if len(item_name) > 2:\n",
            "                    price = float(prices[0].replace('$', ''))\n",
            "                    \n",
            "                    # Look for quantity\n",
            "                    quantity_match = re.search(self.quantity_pattern, line.lower())\n",
            "                    quantity = int(quantity_match.group(1)) if quantity_match else 1\n",
            "                    \n",
            "                    parsed_data['items'].append({\n",
            "                        'name': item_name,\n",
            "                        'quantity': quantity,\n",
            "                        'unit_price': round(price / quantity, 2),\n",
            "                        'total_price': price\n",
            "                    })\n",
            "            \n",
            "            # Extract totals\n",
            "            elif prices:\n",
            "                price_val = float(prices[-1].replace('$', ''))\n",
            "                line_lower = line.lower()\n",
            "                \n",
            "                if 'subtotal' in line_lower:\n",
            "                    parsed_data['subtotal'] = price_val\n",
            "                elif 'tax' in line_lower:\n",
            "                    parsed_data['tax'] = price_val\n",
            "                elif 'total' in line_lower or 'amount' in line_lower:\n",
            "                    parsed_data['total'] = price_val\n",
            "        \n",
            "        return parsed_data\n",
            "\n",
            "# Initialize processor\n",
            "processor = RestaurantOCRProcessor()\n",
            "\n",
            "@app.get(\"/\")\n",
            "async def root():\n",
            "    return {\"message\": \"Restaurant OCR API\", \"status\": \"active\"}\n",
            "\n",
            "@app.post(\"/ocr/menu\", response_model=MenuResponse)\n",
            "async def extract_menu(file: UploadFile = File(...)):\n",
            "    \"\"\"Extract menu data from image\"\"\"\n",
            "    try:\n",
            "        # Validate file type\n",
            "        if not file.content_type.startswith('image/'):\n",
            "            raise HTTPException(status_code=400, detail=\"File must be an image\")\n",
            "        \n",
            "        # Read image\n",
            "        image_bytes = await file.read()\n",
            "        \n",
            "        # Preprocess and extract text\n",
            "        processed_image = processor.preprocess_image(image_bytes)\n",
            "        text, confidence = processor.extract_text(processed_image)\n",
            "        \n",
            "        # Parse as menu\n",
            "        parsed_data = processor.parse_menu(text)\n",
            "        \n",
            "        return MenuResponse(\n",
            "            restaurant_name=parsed_data['restaurant_name'],\n",
            "            sections=parsed_data['sections'],\n",
            "            items=parsed_data['items'],\n",
            "            raw_text=parsed_data['raw_text'],\n",
            "            confidence=confidence\n",
            "        )\n",
            "        \n",
            "    except Exception as e:\n",
            "        logger.error(f\"Menu extraction error: {str(e)}\")\n",
            "        raise HTTPException(status_code=500, detail=f\"Processing error: {str(e)}\")\n",
            "\n",
            "@app.post(\"/ocr/bill\", response_model=BillResponse)\n",
            "async def extract_bill(file: UploadFile = File(...)):\n",
            "    \"\"\"Extract bill data from image\"\"\"\n",
            "    try:\n",
            "        # Validate file type\n",
            "        if not file.content_type.startswith('image/'):\n",
            "            raise HTTPException(status_code=400, detail=\"File must be an image\")\n",
            "        \n",
            "        # Read image\n",
            "        image_bytes = await file.read()\n",
            "        \n",
            "        # Preprocess and extract text\n",
            "        processed_image = processor.preprocess_image(image_bytes)\n",
            "        text, confidence = processor.extract_text(processed_image)\n",
            "        \n",
            "        # Parse as bill\n",
            "        parsed_data = processor.parse_bill(text)\n",
            "        \n",
            "        return BillResponse(\n",
            "            restaurant_name=parsed_data['restaurant_name'],\n",
            "            items=parsed_data['items'],\n",
            "            subtotal=parsed_data['subtotal'],\n",
            "            tax=parsed_data['tax'],\n",
            "            total=parsed_data['total'],\n",
            "            raw_text=parsed_data['raw_text'],\n",
            "            confidence=confidence\n",
            "        )\n",
            "        \n",
            "    except Exception as e:\n",
            "        logger.error(f\"Bill extraction error: {str(e)}\")\n",
            "        raise HTTPException(status_code=500, detail=f\"Processing error: {str(e)}\")\n",
            "\n",
            "@app.post(\"/ocr/text\")\n",
            "async def extract_text_only(file: UploadFile = File(...)):\n",
            "    \"\"\"Extract raw text from image\"\"\"\n",
            "    try:\n",
            "        # Validate file type\n",
            "        if not file.content_type.startswith('image/'):\n",
            "            raise HTTPException(status_code=400, detail=\"File must be an image\")\n",
            "        \n",
            "        # Read image\n",
            "        image_bytes = await file.read()\n",
            "        \n",
            "        # Preprocess and extract text\n",
            "        processed_image = processor.preprocess_image(image_bytes)\n",
            "        text, confidence = processor.extract_text(processed_image)\n",
            "        \n",
            "        return {\n",
            "            \"text\": text,\n",
            "            \"confidence\": confidence,\n",
            "            \"character_count\": len(text),\n",
            "            \"line_count\": len(text.split('\\n'))\n",
            "        }\n",
            "        \n",
            "    except Exception as e:\n",
            "        logger.error(f\"Text extraction error: {str(e)}\")\n",
            "        raise HTTPException(status_code=500, detail=f\"Processing error: {str(e)}\")\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python (venv)",
         "language": "python",
         "name": "venv"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.0"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
